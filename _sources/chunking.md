# Data Chunking

The previous section about [computations with large datasets](https://acdguide.github.io/BigData/computations.html) shows diagrams with various operations computed on chunks of data. Here, we will go into more depth on what chunking is, why it matters, and some real-world examples.

## What is data chunking?

In order to save and analyze large datasets, it is often necessary to split the data into smaller pieces, which are called *chunks*. These smaller chunks can allow for easier and quicker reading/writing and computations of the data. However, if the chunking is done in a suboptimal way, it can sometimes lead to slower computations or other negative performance outputs.

## Why chunking matters

Chunking can have significant implications for performance of both data reading/writing and data computation. See [this article](https://www.unidata.ucar.edu/blogs/developer/en/entry/chunking_data_why_it_matters) for more details on why chunking matters.

## Chunking in the real world

Examples will be added here soon!