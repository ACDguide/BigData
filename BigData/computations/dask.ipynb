{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "familiar-episode",
   "metadata": {},
   "source": [
    "# Dask and chunking in the real world\n",
    "\n",
    "The [data formats section](../data/data-chunking.md) introduces NetCDF chunking, the previous chapter on computations(computations.ipynb) introduces dask and shows how to visualise chunks and how they can affect data analysis. This section illustrate some examples of functions that make use of chunking to make data analysis more efficient and solve memory issues.\n",
    "\n",
    "```{note}\n",
    "Dask has a comprehensive but accessible [blog introducing chunks](https://blog.dask.org/2021/11/02/choosing-dask-chunk-sizes), including how to choose an optimal chunk size in dask and how to align chunks to the original file chunks.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "magnetic-jamaica",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "## This is setup for the plots later on in the notebook - on the website this\n",
    "## cell (and the cells making the diagrams) is hidden by default, using the 'hide-input' cell tag\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numbers\n",
    "import numpy\n",
    "\n",
    "def draw_chunks(ax, size = (10, 8), nchunks = (5, 2), chunk_size = None, chunk_color = None):\n",
    "    \"\"\"\n",
    "    Draw a chunk diagram\n",
    "    \n",
    "    Args:\n",
    "        ax:          matplotlib.pyplot axis to draw on\n",
    "        size:        size of the array (x, y)\n",
    "        nchunks:     number of chunks (x, y)\n",
    "        chunk_size:  size of each chunk (x, y) (default size/nchunks)\n",
    "        chunk_color: colour of each chunk (array with shape nchunks)\n",
    "    \"\"\"\n",
    "    \n",
    "    spacing = 0.1\n",
    "    \n",
    "    if chunk_size is None:\n",
    "        chunk_size = (None, None)\n",
    "        \n",
    "    if chunk_color is None:\n",
    "        chunk_color = numpy.full(nchunks, 'wheat')\n",
    "    else:\n",
    "        chunk_color = numpy.asarray(chunk_color)\n",
    "        \n",
    "    # Fill in None values\n",
    "    chunk_size = tuple(chunk_size[i] if chunk_size[i] is not None else size[i] / nchunks[i]\n",
    "                        for i in range(2))\n",
    "    \n",
    "    if isinstance(chunk_size[0], numbers.Number):\n",
    "        xsize = numpy.full(nchunks[0], chunk_size[0]) - spacing\n",
    "    else:\n",
    "        xsize = numpy.asarray(chunk_size[0]) - spacing\n",
    "        \n",
    "    if isinstance(chunk_size[1], numbers.Number):\n",
    "        ysize = numpy.full(nchunks[1], chunk_size[1]) - spacing\n",
    "    else:\n",
    "        ysize = numpy.asarray(chunk_size[1]) - spacing\n",
    "\n",
    "                        \n",
    "    # Chunk cell centre\n",
    "    xc = (numpy.arange(nchunks[0], dtype='f') + 0.5) * (size[0] / nchunks[0])\n",
    "    yc = (numpy.arange(nchunks[1], dtype='f') + 0.5) * (size[1] / nchunks[1])\n",
    "    \n",
    "    for ii in range(nchunks[0]):\n",
    "        for jj in range(nchunks[1]):\n",
    "            box = matplotlib.patches.Rectangle((xc[ii] - xsize[ii]/2,\n",
    "                                                yc[jj] - ysize[jj]/2),\n",
    "                                               xsize[ii],\n",
    "                                               ysize[jj], \n",
    "                                               facecolor=chunk_color[ii,jj], edgecolor='black')\n",
    "            \n",
    "            ax.add_patch(box)\n",
    "            \n",
    "    ax.set_xbound(0, size[0])\n",
    "    ax.set_ylim(0, size[1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_frame_on(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88532ca6",
   "metadata": {},
   "source": [
    "## Rechunking\n",
    "\n",
    "To rechunk a dataset is to read it in and write it back out again, but in a way that's optimised for analysis in a different dimension - e.g. you might have a dataset that's optimised to read lat-lon slices, but you want to create a time-series climatology.\n",
    "\n",
    "Rechunking may also combine multiple input files - say a dataset has one file per model day that contains all of its variables, for a timeseries analysis you may want to swap this to one file per variable per model year to reduce the number of files that need to be opened in the analysis.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<b>Resources</b>\n",
    "\n",
    " - **Xarray** The [encoding](http://xarray.pydata.org/en/stable/user-guide/io.html#chunk-based-compression) argument to `to_dataset()` can specify file chunking, combine multiple files with [open_mfdataset](http://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html) or [concat](http://xarray.pydata.org/en/stable/generated/xarray.concat.html)\n",
    " - [**Rechunker**](https://github.com/pangeo-data/rechunker) A Python library for rechunking files in *Zarr* format\n",
    " - **NCO** There are several arguments to specify output chunking, see e.g. `ncks --help | grep cnk`. To combine input files along time see `ncrcat`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0590d7",
   "metadata": {},
   "source": [
    "## Simple function to retrieve file chunks\n",
    "\n",
    "[This blog](https://climate-cms.org/posts/2021-07-29-coarsen_climatology.html) includes a simple function to retrieve a netcdf file chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3b578",
   "metadata": {},
   "source": [
    "## Chunks effects on parallel computations with dask\n",
    "\n",
    "This [parallel training](https://coecms-training.github.io/parallel/dask-intro.html) has many references to chunks and their effects on computation in its dask and case studies sections.\n",
    "!!!Any more example on map_blocks would be brillinat as it is hard to find them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471c11c",
   "metadata": {},
   "source": [
    "## Using map_blocks\n",
    "\n",
    "Dask provides the dask.array.map_blocks() function that allows you to run a function on every chunk of an array.\n",
    "The last section of [this blog](https://climate-cms.org/posts/2021-11-24-api.html?highlight=chunk#pure-dask-advanced) shows an example of how to use map_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51668ab",
   "metadata": {},
   "source": [
    "## Using dask delayed\n",
    "\n",
    "Dask ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833bc64",
   "metadata": {},
   "source": [
    "## Using dask futures\n",
    "\n",
    "Dask ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf4c69e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
